{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the Best Classifier for Place Names labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules need to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "from _search import ParamSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods need for the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read feature vectors into numpy array\n",
    "def read_vectors(filename):\n",
    "\t# Read raw table from file\n",
    "\tdf = read_csv(filename,error_bad_lines=False)\n",
    "\tfeature_keys = list(df.keys())\n",
    "\t# test soundex\n",
    "\t# feature_keys.remove('soundex')\n",
    "\tfeature_keys.remove('is_target')\n",
    "\tdata = []\n",
    "\tfor i in range(len(df.values)):\n",
    "\t\tnew_row = []\n",
    "\t\tfor key in feature_keys:\n",
    "\n",
    "\t\t\tnew_row += [df[key][i]]\n",
    "\t\tdata += [new_row]\n",
    "\t# for d in data:\n",
    "\t# \tprint(d)\n",
    "\ttarget = list(df['is_target'].values)\n",
    "\treturn {'data':data, 'target':target, 'feature':feature_keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performs model training\n",
    "def train_model(dataset):\n",
    "\tclf = svm.SVC()\n",
    "\tclf.fit(dataset['data'], dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform model selection (new version)\n",
    "def model_select(param_grid, X, y, numFolds):\n",
    "\tverbose = param_grid.pop('verbose', False)\n",
    "\twarnings = param_grid.pop('warnings', True)\n",
    "\tprocesses = param_grid.pop('processes', True)\n",
    "\tbatch_size = param_grid.pop('batch_size', True)\n",
    "\n",
    "\tmycv = StratifiedKFold(n_splits=numFolds, shuffle=True)\n",
    "\tbest_params = {}\n",
    "\tfor key in sorted(param_grid):\n",
    "\t\tprint('-------------------------------------------------')\n",
    "\t\tprint('{} classifier parameter searching'.format(key))\n",
    "\t\tprint()\n",
    "\t\tclf = ParamSearch(eval(key)(), param_grid[key], cv=mycv, \n",
    "\t\t\t\t\t\t\twarnings=warnings, verbose=verbose, batch_size=batch_size)\n",
    "\t\tclf.grid_search(X, y, processes=processes)\n",
    "\t\tbest_params[key] = clf.best_param\n",
    "\treturn best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_grid_gen(tune_one_clf=False):\n",
    "\t# SVM Classifier\n",
    "\tsvmList = {'kernel':['rbf'], 'gamma':[1e-5, 1e-3, 1], 'C':[0.01, 0.1, 1, 10]}\n",
    "\n",
    "\t# Random Forest Classifier\n",
    "\trfList = [\n",
    "\t\t{'n_estimators': [10, 30, 50], 'criterion':['gini','entropy'],'max_features':[0.2, 0.5,'sqrt','log2',None]},\n",
    "\t\t{'max_depth': [5, 10, None], 'min_samples_split': [2, 5, 10, 20],'min_samples_leaf': [2, 5, 10, 20]},\n",
    "\t\t{'n_estimators': [10, 30, 50], 'min_weight_fraction_leaf': [0, 0.01], 'min_impurity_split': [1e-7, 1e-5, 1e-3]},\n",
    "\t\t{'n_estimators': [10, 30, 50], 'bootstrap': [True, False], 'class_weight': ['balanced', None]} ]\n",
    "\n",
    "\t# Logistic Regression Classifier\n",
    "\tlogisList = [{'penalty':['l1','l2'], 'C':[1e-3, 1e-2,1,10],\n",
    "\t\t\t\t  'solver':['liblinear'], 'class_weight':['balanced',None]},\n",
    "\t\t\t\t  {'C':[1e-3, 1e-2,1,10], 'class_weight':['balanced',None],\n",
    "\t\t\t\t  'solver':['newton-cg','lbfgs','sag']}]\n",
    "\n",
    "\t# Decision Tree Classifier\n",
    "\ttreeList = [{'criterion':['gini','entropy'], 'splitter':['best','random'],\n",
    "\t\t\t\t'max_features':[0.2,0.5,'sqrt','log2',None]},\n",
    "\t\t\t\t{'max_depth':[5,10,None], 'min_samples_split':[2,5,10,20],\n",
    "\t\t\t\t'min_samples_leaf':[2,5,10,20]},\n",
    "\t\t\t\t{'min_weight_fraction_leaf':[0, 0.01],\n",
    "\t\t\t\t'class_weight':['balanced',None], 'min_impurity_split':[1e-7,1e-5,1e-3]}]\n",
    "\n",
    "\tparam_grid = {}\n",
    "\tparam_grid.update({'verbose': True})\n",
    "\tparam_grid.update({'warnings': False})\n",
    "\tparam_grid.update({'processes': 8})\n",
    "\tparam_grid.update({'batch_size': 30})\n",
    "\tif not tune_one_clf:\n",
    "\t\tparam_grid.update({'svm.SVC': svmList})\n",
    "\t\tparam_grid.update({'RandomForestClassifier': rfList})\n",
    "\t\tparam_grid.update({'tree.DecisionTreeClassifier': treeList})\n",
    "\t\tparam_grid.update({'linear_model.LogisticRegression':logisList})\n",
    "\telse:\n",
    "\t\trfList = [\n",
    "\t\t\t{'n_estimators': [10, 30, 50], 'criterion': ['gini', 'entropy'],\n",
    "\t\t\t 'max_features': [0.2, 0.5, 'sqrt', 'log2', None]},\n",
    "\t\t\t{'max_depth': [5, 10, None], 'min_samples_split': [2, 5, 10, 20],\n",
    "\t\t\t 'min_samples_leaf': [2, 5, 10, 20]},\n",
    "\t\t\t{'n_estimators': [10, 30, 50], 'min_weight_fraction_leaf': [0, 0.01],\n",
    "\t\t\t 'min_impurity_split': [1e-7, 1e-5, 1e-3]},\n",
    "\t\t\t{'n_estimators': [10, 30, 50], 'bootstrap': [True, False], 'class_weight': ['balanced', None]}]\n",
    "\t\tparam_grid.update({'RandomForestClassifier': rfList})\n",
    "\treturn param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stat(clf, X, y, split_ratio=0.2, feature_names=None, printTree=False):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=10, stratify=y)\n",
    "\tclf.fit(X_train, y_train)\n",
    "\t# Confusion matrix on training set\n",
    "\ty_true, y_predict = y_train, clf.predict(X_train)\n",
    "\tprint('Training Set Performance')\n",
    "\tprint(confusion_matrix(y_true, y_predict))\n",
    "\t# Confusion matrix on testing set\n",
    "\ty_true, y_predict = y_test, clf.predict(X_test)\n",
    "\tprint(\"Testing Set Performance\")\n",
    "\tprint(confusion_matrix(y_true, y_predict))\n",
    "\tprint('Classification report on testing set')\n",
    "\tprint('precision score: {}'.format(precision_score(y_true, y_predict)))\n",
    "\tprint('Scores:\\n{}'.format(classification_report(y_true, y_predict)))\n",
    "\t## only for decision tree\n",
    "\tif printTree:\n",
    "\t\tdot_data = tree.export_graphviz(clf, out_file=None,feature_names=feature_names)\n",
    "\t\tgraph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\t\tgraph.write_pdf(\"tree.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_regression(X, y, folds=5, threshold=0.5):\n",
    "\tprint(\"linear regression:\")\n",
    "\treg = linear_model.LinearRegression()\n",
    "\tskf = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "\tprecision = []\n",
    "\trecall = []\n",
    "\tf1 = []\n",
    "\tX = np.array(X)\n",
    "\ty = np.array(y)\n",
    "\tfor train, test in skf.split(X, y):\n",
    "\t\tX_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\t\treg.fit(X_train,y_train)\n",
    "\t\ty_pred = reg.predict(X_test)\n",
    "\t\ty_pred[y_pred>=threshold] = 1\n",
    "\t\ty_pred[y_pred<threshold] = 0\n",
    "\t\tprecision.append(precision_score(y_test, y_pred))\n",
    "\t\trecall.append(recall_score(y_test,y_pred))\n",
    "\t\tf1.append(f1_score(y_test,y_pred))\n",
    "\t\tprint(confusion_matrix(y_test, y_pred))\n",
    "\tprint(\"{} fold cross validation score:\".format(folds))\n",
    "\tprint(\"precision:{:6.3f} +/-{:6.3f} recall:{:6.3f} +/-{:6.3f}\".format(np.mean(precision), np.std(precision), np.mean(recall), np.std(recall)))\n",
    "\tprint(\"f1:{:6.3f} +/-{:6.3f}\".format(np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(X_test, y_test, clf):\n",
    "\tprint('Testing trained model of testing set:')\n",
    "\ty_true, y_predict = y_test, clf.predict(X_test)\n",
    "\tprint(\"Testing Set Performance\")\n",
    "\tprint(confusion_matrix(y_true, y_predict))\n",
    "\tprint('Classification report on testing set')\n",
    "\tprint('Scores:\\n{}'.format(classification_report(y_true, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Development Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../data/devl_set_feature_vectors.txt'\n",
    "dataSet = read_vectors(filename)\n",
    "X, y = dataSet['data'], dataSet['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the decision tree out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Performance\n",
      "[[2593    0]\n",
      " [   0 1297]]\n",
      "Testing Set Performance\n",
      "[[603  46]\n",
      " [ 28 296]]\n",
      "Classification report on testing set\n",
      "precision score: 0.865497076023\n",
      "Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.93      0.94       649\n",
      "        1.0       0.87      0.91      0.89       324\n",
      "\n",
      "avg / total       0.93      0.92      0.92       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_stat(tree.DecisionTreeClassifier(), X, y, feature_names=dataSet['feature'],printTree=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression:\n",
      "[[593  56]\n",
      " [ 13 312]]\n",
      "[[583  66]\n",
      " [ 13 311]]\n",
      "[[588  60]\n",
      " [  7 317]]\n",
      "[[570  78]\n",
      " [ 13 311]]\n",
      "[[590  58]\n",
      " [ 16 308]]\n",
      "5 fold cross validation score:\n",
      "precision: 0.831 +/- 0.017 recall: 0.962 +/- 0.009\n",
      "f1: 0.891 +/- 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yin/miniconda2/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_regression(X, y, folds=5, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "* Four Classifiers are tested with a serials of parameters \n",
    "* The parameters are generated using param_grid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "RandomForestClassifier classifier parameter searching\n",
      "()\n",
      "Precision  0.907 +/- 0.024  Recall  0.946 +/- 0.022 for \n",
      "{'max_features': 0.2, 'n_estimators': 10, 'criterion': 'gini'}\n",
      "Precision  0.900 +/- 0.029  Recall  0.947 +/- 0.028 for \n",
      "{'min_samples_split': 2, 'max_depth': 5, 'min_samples_leaf': 2}\n",
      "\n",
      "Precision  0.904 +/- 0.024  Recall  0.922 +/- 0.029 for \n",
      "{'min_samples_split': 5, 'max_depth': 5, 'min_samples_leaf': 2}\n",
      "Precision  0.903 +/- 0.012  Recall  0.961 +/- 0.013 for \n",
      "{'max_features': 0.2, 'n_estimators': 30, 'criterion': 'gini'}Precision  0.903 +/- 0.018  Recall  0.936 +/- 0.022 for \n",
      "{'min_samples_split': 10, 'max_depth': 5, 'min_samples_leaf': 2}\n",
      "\n",
      "Precision  0.916 +/- 0.012  Recall  0.891 +/- 0.071 for \n",
      "{'min_samples_split': 20, 'max_depth': 5, 'min_samples_leaf': 2}\n",
      "Precision  0.908 +/- 0.027  Recall  0.931 +/- 0.030 for \n",
      "{'min_samples_split': 10, 'max_depth': 10, 'min_samples_leaf': 20}\n",
      "Precision  0.920 +/- 0.009  Recall  0.864 +/- 0.043 for \n",
      "{'min_samples_split': 2, 'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Precision  0.917 +/- 0.017  Recall  0.904 +/- 0.034 for \n",
      "{'min_samples_split': 20, 'max_depth': 10, 'min_samples_leaf': 20}Precision  0.929 +/- 0.016  Recall  0.853 +/- 0.094 for \n",
      "{'min_samples_split': 5, 'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Precision  0.902 +/- 0.011  Recall  0.956 +/- 0.004 for \n",
      "{'min_samples_split': 2, 'max_depth': None, 'min_samples_leaf': 2}\n",
      "Precision  0.915 +/- 0.023  Recall  0.866 +/- 0.058 for \n",
      "{'min_samples_split': 10, 'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Precision  0.912 +/- 0.023  Recall  0.940 +/- 0.015 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.907 +/- 0.011  Recall  0.959 +/- 0.017 for \n",
      "{'min_samples_split': 5, 'max_depth': None, 'min_samples_leaf': 2}\n",
      "Precision  0.909 +/- 0.021  Recall  0.929 +/- 0.042 for \n",
      "{'min_samples_split': 20, 'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Precision  0.903 +/- 0.018  Recall  0.964 +/- 0.015 for \n",
      "{'max_features': 0.2, 'n_estimators': 50, 'criterion': 'gini'}\n",
      "Precision  0.908 +/- 0.006  Recall  0.956 +/- 0.010 for \n",
      "{'min_samples_split': 10, 'max_depth': None, 'min_samples_leaf': 2}\n",
      "Precision  0.888 +/- 0.027  Recall  0.873 +/- 0.073 for \n",
      "{'min_samples_split': 2, 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "Precision  0.906 +/- 0.009  Recall  0.949 +/- 0.007 for \n",
      "{'max_features': 0.5, 'n_estimators': 10, 'criterion': 'gini'}\n",
      "Precision  0.914 +/- 0.006  Recall  0.858 +/- 0.053 for \n",
      "{'min_samples_split': 5, 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "Precision  0.906 +/- 0.012  Recall  0.955 +/- 0.015 for \n",
      "{'min_samples_split': 20, 'max_depth': None, 'min_samples_leaf': 2}\n",
      "Precision  0.910 +/- 0.012  Recall  0.957 +/- 0.014 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.908 +/- 0.011  Recall  0.901 +/- 0.047 for \n",
      "{'min_samples_split': 10, 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "Precision  0.906 +/- 0.015  Recall  0.947 +/- 0.008 for \n",
      "{'min_samples_split': 2, 'max_depth': None, 'min_samples_leaf': 5}\n",
      "Precision  0.902 +/- 0.028  Recall  0.940 +/- 0.053 for \n",
      "{'min_samples_split': 20, 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "Precision  0.908 +/- 0.012  Recall  0.953 +/- 0.007 for \n",
      "{'min_samples_split': 5, 'max_depth': None, 'min_samples_leaf': 5}\n",
      "Precision  0.918 +/- 0.017  Recall  0.888 +/- 0.065 for \n",
      "{'min_samples_split': 2, 'max_depth': 5, 'min_samples_leaf': 20}\n",
      "Precision  0.901 +/- 0.007  Recall  0.959 +/- 0.008 for \n",
      "{'min_samples_split': 10, 'max_depth': None, 'min_samples_leaf': 5}\n",
      "Precision  0.916 +/- 0.015  Recall  0.870 +/- 0.052 for \n",
      "{'min_samples_split': 5, 'max_depth': 5, 'min_samples_leaf': 20}\n",
      "Precision  0.906 +/- 0.011  Recall  0.963 +/- 0.008 for \n",
      "{'max_features': 0.5, 'n_estimators': 30, 'criterion': 'gini'}\n",
      "Precision  0.902 +/- 0.004  Recall  0.954 +/- 0.010 for \n",
      "{'min_samples_split': 20, 'max_depth': None, 'min_samples_leaf': 5}\n",
      "Precision  0.912 +/- 0.025  Recall  0.880 +/- 0.104 for \n",
      "{'min_samples_split': 10, 'max_depth': 5, 'min_samples_leaf': 20}\n",
      "Precision  0.905 +/- 0.003  Recall  0.937 +/- 0.030 for \n",
      "{'min_samples_split': 2, 'max_depth': None, 'min_samples_leaf': 10}\n",
      "Precision  0.907 +/- 0.010  Recall  0.871 +/- 0.089 for \n",
      "{'min_samples_split': 20, 'max_depth': 5, 'min_samples_leaf': 20}\n",
      "Precision  0.906 +/- 0.021  Recall  0.964 +/- 0.009 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.900 +/- 0.014  Recall  0.959 +/- 0.018 for \n",
      "{'min_samples_split': 5, 'max_depth': None, 'min_samples_leaf': 10}\n",
      "Precision  0.899 +/- 0.015  Recall  0.950 +/- 0.017 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.902 +/- 0.012  Recall  0.963 +/- 0.018 for \n",
      "{'min_samples_split': 2, 'max_depth': 10, 'min_samples_leaf': 2}\n",
      "Precision  0.901 +/- 0.005  Recall  0.950 +/- 0.006 for \n",
      "{'min_samples_split': 10, 'max_depth': None, 'min_samples_leaf': 10}\n",
      "Precision  0.907 +/- 0.014  Recall  0.958 +/- 0.003 for \n",
      "{'min_samples_split': 5, 'max_depth': 10, 'min_samples_leaf': 2}\n",
      "Precision  0.904 +/- 0.011  Recall  0.955 +/- 0.017 for \n",
      "{'min_samples_split': 20, 'max_depth': None, 'min_samples_leaf': 10}\n",
      "Precision  0.904 +/- 0.021  Recall  0.952 +/- 0.011 for \n",
      "{'min_samples_split': 10, 'max_depth': 10, 'min_samples_leaf': 2}\n",
      "Precision  0.910 +/- 0.006  Recall  0.934 +/- 0.017 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.906 +/- 0.016  Recall  0.941 +/- 0.024 for \n",
      "{'min_samples_split': 2, 'max_depth': None, 'min_samples_leaf': 20}\n",
      "Precision  0.904 +/- 0.012  Recall  0.955 +/- 0.008 for \n",
      "{'min_samples_split': 20, 'max_depth': 10, 'min_samples_leaf': 2}\n",
      "Precision  0.904 +/- 0.006  Recall  0.920 +/- 0.019 for \n",
      "{'min_samples_split': 5, 'max_depth': None, 'min_samples_leaf': 20}\n",
      "Precision  0.908 +/- 0.018  Recall  0.947 +/- 0.029 for \n",
      "{'min_samples_split': 2, 'max_depth': 10, 'min_samples_leaf': 5}\n",
      "Precision  0.902 +/- 0.009  Recall  0.973 +/- 0.005 for \n",
      "{'max_features': 0.5, 'n_estimators': 50, 'criterion': 'gini'}\n",
      "Precision  0.899 +/- 0.010  Recall  0.923 +/- 0.036 for \n",
      "{'min_samples_split': 10, 'max_depth': None, 'min_samples_leaf': 20}\n",
      "Precision  0.903 +/- 0.010  Recall  0.952 +/- 0.016 for \n",
      "{'min_samples_split': 5, 'max_depth': 10, 'min_samples_leaf': 5}\n",
      "Precision  0.906 +/- 0.014  Recall  0.945 +/- 0.008 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 10, 'criterion': 'gini'}\n",
      "Precision  0.903 +/- 0.019  Recall  0.933 +/- 0.043 for \n",
      "{'min_samples_split': 20, 'max_depth': None, 'min_samples_leaf': 20}\n",
      "Precision  0.905 +/- 0.014  Recall  0.951 +/- 0.025 for \n",
      "{'min_samples_split': 10, 'max_depth': 10, 'min_samples_leaf': 5}\n",
      "Precision  0.906 +/- 0.014  Recall  0.947 +/- 0.013 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 0.001, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.910 +/- 0.018  Recall  0.933 +/- 0.012 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.902 +/- 0.013  Recall  0.954 +/- 0.017 for \n",
      "{'min_samples_split': 20, 'max_depth': 10, 'min_samples_leaf': 5}\n",
      "Precision  0.913 +/- 0.008  Recall  0.938 +/- 0.008 for \n",
      "{'n_estimators': 10, 'bootstrap': True, 'class_weight': 'balanced'}\n",
      "Precision  0.896 +/- 0.014  Recall  0.955 +/- 0.016 for \n",
      "{'min_samples_split': 2, 'max_depth': 10, 'min_samples_leaf': 10}\n",
      "Precision  0.902 +/- 0.007  Recall  0.957 +/- 0.013 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 30, 'criterion': 'gini'}\n",
      "Precision  0.907 +/- 0.017  Recall  0.922 +/- 0.056 for \n",
      "{'min_samples_split': 5, 'max_depth': 10, 'min_samples_leaf': 10}\n",
      "Precision  0.908 +/- 0.011  Recall  0.959 +/- 0.005 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.908 +/- 0.015  Recall  0.938 +/- 0.015 for \n",
      "{'min_samples_split': 10, 'max_depth': 10, 'min_samples_leaf': 10}\n",
      "Precision  0.905 +/- 0.006  Recall  0.954 +/- 0.011 for \n",
      "{'n_estimators': 30, 'bootstrap': True, 'class_weight': 'balanced'}\n",
      "Precision  0.908 +/- 0.016  Recall  0.940 +/- 0.037 for \n",
      "{'min_samples_split': 20, 'max_depth': 10, 'min_samples_leaf': 10}\n",
      "Precision  0.905 +/- 0.016  Recall  0.944 +/- 0.015 for \n",
      "{'min_samples_split': 2, 'max_depth': 10, 'min_samples_leaf': 20}\n",
      "Precision  0.908 +/- 0.010  Recall  0.913 +/- 0.056 for \n",
      "{'min_samples_split': 5, 'max_depth': 10, 'min_samples_leaf': 20}\n",
      "Precision  0.907 +/- 0.006  Recall  0.969 +/- 0.004 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 50, 'criterion': 'gini'}\n",
      "Precision  0.908 +/- 0.021  Recall  0.930 +/- 0.016 for \n",
      "{'max_features': 'log2', 'n_estimators': 10, 'criterion': 'gini'}\n",
      "Precision  0.906 +/- 0.015  Recall  0.962 +/- 0.015 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.906 +/- 0.009  Recall  0.931 +/- 0.027 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.906 +/- 0.006  Recall  0.959 +/- 0.004 for \n",
      "{'n_estimators': 50, 'bootstrap': True, 'class_weight': 'balanced'}\n",
      "Precision  0.913 +/- 0.023  Recall  0.934 +/- 0.015 for \n",
      "{'n_estimators': 10, 'bootstrap': True, 'class_weight': None}\n",
      "Precision  0.909 +/- 0.014  Recall  0.951 +/- 0.012 for \n",
      "{'max_features': 'log2', 'n_estimators': 30, 'criterion': 'gini'}\n",
      "Precision  0.906 +/- 0.018  Recall  0.942 +/- 0.021 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.906 +/- 0.018  Recall  0.960 +/- 0.010 for \n",
      "{'n_estimators': 30, 'bootstrap': True, 'class_weight': None}\n",
      "Precision  0.907 +/- 0.009  Recall  0.958 +/- 0.006 for \n",
      "{'max_features': 'log2', 'n_estimators': 50, 'criterion': 'gini'}\n",
      "Precision  0.911 +/- 0.011  Recall  0.939 +/- 0.014 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 1e-07, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.912 +/- 0.011  Recall  0.941 +/- 0.009 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.905 +/- 0.016  Recall  0.956 +/- 0.005 for \n",
      "{'max_features': None, 'n_estimators': 10, 'criterion': 'gini'}\n",
      "Precision  0.908 +/- 0.011  Recall  0.962 +/- 0.011 for \n",
      "{'n_estimators': 50, 'bootstrap': True, 'class_weight': None}\n",
      "Precision  0.912 +/- 0.014  Recall  0.934 +/- 0.008 for \n",
      "{'n_estimators': 10, 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Precision  0.903 +/- 0.011  Recall  0.962 +/- 0.007 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.911 +/- 0.016  Recall  0.954 +/- 0.014 for \n",
      "{'n_estimators': 30, 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Precision  0.898 +/- 0.016  Recall  0.967 +/- 0.007 for \n",
      "{'max_features': None, 'n_estimators': 30, 'criterion': 'gini'}\n",
      "Precision  0.905 +/- 0.012  Recall  0.964 +/- 0.013 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0}\n",
      "Precision  0.894 +/- 0.009  Recall  0.925 +/- 0.021 for \n",
      "{'n_estimators': 10, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.910 +/- 0.017  Recall  0.939 +/- 0.016 for \n",
      "{'n_estimators': 30, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.902 +/- 0.016  Recall  0.956 +/- 0.011 for \n",
      "{'n_estimators': 50, 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Precision  0.915 +/- 0.007  Recall  0.937 +/- 0.016 for \n",
      "{'n_estimators': 10, 'bootstrap': False, 'class_weight': None}\n",
      "Precision  0.906 +/- 0.015  Recall  0.940 +/- 0.018 for \n",
      "{'n_estimators': 50, 'min_impurity_split': 1e-05, 'min_weight_fraction_leaf': 0.01}\n",
      "Precision  0.910 +/- 0.012  Recall  0.957 +/- 0.007 for \n",
      "{'n_estimators': 30, 'bootstrap': False, 'class_weight': None}\n",
      "Precision  0.903 +/- 0.010  Recall  0.974 +/- 0.005 for \n",
      "{'max_features': None, 'n_estimators': 50, 'criterion': 'gini'}\n",
      "Precision  0.918 +/- 0.010  Recall  0.948 +/- 0.011 for \n",
      "{'max_features': 0.2, 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "Precision  0.909 +/- 0.007  Recall  0.960 +/- 0.005 for \n",
      "{'max_features': 0.2, 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "Precision  0.909 +/- 0.018  Recall  0.964 +/- 0.005 for \n",
      "{'n_estimators': 50, 'bootstrap': False, 'class_weight': None}\n",
      "Precision  0.905 +/- 0.018  Recall  0.964 +/- 0.006 for \n",
      "{'max_features': 0.2, 'n_estimators': 50, 'criterion': 'entropy'}\n",
      "Precision  0.900 +/- 0.011  Recall  0.943 +/- 0.022 for \n",
      "{'max_features': 0.5, 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "Precision  0.903 +/- 0.015  Recall  0.961 +/- 0.006 for \n",
      "{'max_features': 0.5, 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "Precision  0.904 +/- 0.022  Recall  0.977 +/- 0.003 for \n",
      "{'max_features': 0.5, 'n_estimators': 50, 'criterion': 'entropy'}\n",
      "Precision  0.914 +/- 0.014  Recall  0.940 +/- 0.014 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "Precision  0.906 +/- 0.017  Recall  0.961 +/- 0.011 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "Precision  0.904 +/- 0.024  Recall  0.966 +/- 0.005 for \n",
      "{'max_features': 'sqrt', 'n_estimators': 50, 'criterion': 'entropy'}\n",
      "Precision  0.913 +/- 0.010  Recall  0.929 +/- 0.020 for \n",
      "{'max_features': 'log2', 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "Precision  0.907 +/- 0.013  Recall  0.957 +/- 0.014 for \n",
      "{'max_features': 'log2', 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "Precision  0.908 +/- 0.007  Recall  0.962 +/- 0.015 for \n",
      "{'max_features': 'log2', 'n_estimators': 50, 'criterion': 'entropy'}\n",
      "Precision  0.904 +/- 0.017  Recall  0.948 +/- 0.012 for \n",
      "{'max_features': None, 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "Precision  0.906 +/- 0.017  Recall  0.978 +/- 0.011 for \n",
      "{'max_features': None, 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "Precision  0.902 +/- 0.018  Recall  0.976 +/- 0.012 for \n",
      "{'max_features': None, 'n_estimators': 50, 'criterion': 'entropy'}\n",
      "()\n",
      "Best f1 score:  0.940 +/- 0.004\n",
      "Precision  0.906 +/- 0.017  Recall  0.978 +/- 0.011\n",
      "Best parameter found based on f1: \n",
      "{'max_features': None, 'n_estimators': 30, 'criterion': 'entropy'}\n",
      "-------------------------------------------------\n",
      "RandomForestClassifier classifier\n",
      "()\n",
      "{'f1': 0.94015055191338193, 'recall': 0.97778537511870844, 'f1_std': 0.004076998851443049, 'precision': 0.90567732764242947, 'precision_std': 0.016520562822866895, 'parameter': {'max_features': None, 'n_estimators': 30, 'criterion': 'entropy'}, 'recall_std': 0.011117872635256123}\n"
     ]
    }
   ],
   "source": [
    "params = param_grid_gen(tune_one_clf=True)\n",
    "best_params = model_select(params, X, y, 5)\n",
    "for key in sorted(best_params):\n",
    "    print('-------------------------------------------------')\n",
    "    print('{} classifier'.format(key))\n",
    "    print()\n",
    "    print(best_params[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we test different parameter of Random Forest\n",
    "We split development set into P set and Q set: P set for training and Q set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Random Forest gives different results every run. So the average is taken after 20 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.920 (+/- 0.013)\n",
      "recall:  0.908 (+/- 0.041)\n",
      "f1:  0.913 (+/- 0.016)\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "clf_matrix=[]\n",
    "for i in range(20):\n",
    "    clf=RandomForestClassifier(n_estimators=30,min_samples_split=5,max_depth=5,max_features='log2',\n",
    "                              min_samples_leaf=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_true, y_predict = y_test, clf.predict(X_test)\n",
    "    precision.append(precision_score(y_true, y_predict))\n",
    "    recall.append(recall_score(y_true, y_predict))\n",
    "    f1.append(f1_score(y_true,y_predict))\n",
    "    clf_matrix.append(confusion_matrix(y_true,y_predict))\n",
    "print('precision: {:6.3f} (+/-{:6.3f})'.format(np.mean(precision),np.std(precision)))\n",
    "print('recall: {:6.3f} (+/-{:6.3f})'.format(np.mean(recall),np.std(recall)))\n",
    "print('f1: {:6.3f} (+/-{:6.3f})'.format(np.mean(f1),np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1556.25    64.75]\n",
      " [   74.45   736.55]]\n",
      "[[ 13.63405662  13.63405662]\n",
      " [ 33.0673177   33.0673177 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(clf_matrix,axis=0))\n",
    "print(np.std(clf_matrix,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After parameter tuning, we need to re-verify the parameters by cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverify the parameters by CV\n",
      "cross_validaiton score\n",
      "precision: 0.9172239240675054 (+/-0.021584022423820425)\n",
      "recall: 0.9296410256410257 (+/-0.04675534923054424)\n",
      "f1: 0.9080189466431943 (+/-0.009671176748588209)\n"
     ]
    }
   ],
   "source": [
    "print('Reverify the parameters by CV')\n",
    "my_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "clf=RandomForestClassifier(n_estimators=30,min_samples_split=5,max_depth=5,max_features='log2',\n",
    "                              min_samples_leaf=5)\n",
    "precision_scores = cross_val_score(clf,X, y, cv=my_cv, scoring='precision' )\n",
    "recall_scores = cross_val_score(clf, X, y, cv=my_cv, scoring='recall' )\n",
    "f1_scores = cross_val_score(clf, X, y, cv=my_cv, scoring='f1' )\n",
    "print('cross_validaiton score')\n",
    "print('precision: {} (+/-{})'.format(np.mean(precision_scores),np.std(precision_scores)))\n",
    "print('recall: {} (+/-{})'.format(np.mean(recall_scores),np.std(recall_scores)))\n",
    "print('f1: {} (+/-{})'.format(np.mean(f1_scores),np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained model of testing set:\n",
      "Testing Set Performance\n",
      "[[1804   78]\n",
      " [  51  890]]\n",
      "Classification report on testing set\n",
      "Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.96      0.97      1882\n",
      "        1.0       0.92      0.95      0.93       941\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test_set_feature_vectors.txt'\n",
    "dataSet = read_vectors(filename)\n",
    "X_test, y_test = dataSet['data'], dataSet['target']\n",
    "clf = RandomForestClassifier(max_depth=4, max_features=0.2)\n",
    "clf.fit(X,y)\n",
    "test_model(X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained model of testing set:\n",
      "Testing Set Performance\n",
      "[[1824   58]\n",
      " [  91  850]]\n",
      "Classification report on testing set\n",
      "Scores:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.97      0.96      1882\n",
      "        1.0       0.94      0.90      0.92       941\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X,y)\n",
    "test_model(X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average score of 20 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.935 (+/- 0.011)\n",
      "recall:  0.902 (+/- 0.052)\n",
      "f1:  0.917 (+/- 0.023)\n",
      "[[ 1822.65    59.35]\n",
      " [   91.85   849.15]]\n",
      "[[ 13.82850317  13.82850317]\n",
      " [ 48.9512768   48.9512768 ]]\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "clf_matrix=[]\n",
    "for i in range(20):\n",
    "    clf=RandomForestClassifier(n_estimators=30,min_samples_split=5,max_depth=5,max_features='log2',\n",
    "                              min_samples_leaf=5)\n",
    "    clf.fit(X, y)\n",
    "    y_true, y_predict = y_test, clf.predict(X_test)\n",
    "    precision.append(precision_score(y_true, y_predict))\n",
    "    recall.append(recall_score(y_true, y_predict))\n",
    "    f1.append(f1_score(y_true,y_predict))\n",
    "    clf_matrix.append(confusion_matrix(y_true,y_predict))\n",
    "print('precision: {:6.3f} (+/-{:6.3f})'.format(np.mean(precision),np.std(precision)))\n",
    "print('recall: {:6.3f} (+/-{:6.3f})'.format(np.mean(recall),np.std(recall)))\n",
    "print('f1: {:6.3f} (+/-{:6.3f})'.format(np.mean(f1),np.std(f1)))\n",
    "print(np.mean(clf_matrix,axis=0))\n",
    "print(np.std(clf_matrix,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
